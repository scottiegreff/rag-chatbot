# Local Development Environment Configuration for Weaviate Testing
# Copy this to .env or source it in your shell

# PostgreSQL Database Configuration (for local testing)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ai_chatbot
DB_USER=postgres
DB_PASSWORD=password1234

# Weaviate Vector Database Configuration
WEAVIATE_URL=http://weaviate:8080

# LLM Model Configuration
# CHANGED: Using TinyLlama 1.1B for faster responses
MODEL_PATH=./models/tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf
MODEL_TYPE=llama
MAX_NEW_TOKENS=1024
TEMPERATURE=0.7
TOP_P=0.85
REPETITION_PENALTY=1.1

# Platform-specific optimizations for M1 Mac
CT_METAL=1
CT_CUDA=0
GPU_LAYERS=4
CONTEXT_LENGTH=4096

# RAG Configuration (optimized for local testing)
# Embedding model: intfloat/e5-small (fast, 134MB), intfloat/e5-large (accurate, 438MB), sentence-transformers/all-MiniLM-L6-v2 (balanced, 80MB)
EMBEDDING_MODEL=intfloat/e5-largeENABLE_RAG=true
RAG_USE_CPU=true
CHUNK_SIZE=500
OVERLAP=50

# API Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=true
CORS_ORIGINS=*

# Performance settings
MAX_HISTORY_MESSAGES=50
RAG_CONTEXT_MESSAGES=2
ENABLE_INTERNET_SEARCH=true
SERPAPI_API_KEY=60f4bdb73193cf049d787e582055b6717bba8f88549de9b59184851dc276bd3b
SEARCH_ENGINE=serpapi

# Resource limits removed for t3.medium compatibility
MEMORY_LIMIT=8G
MEMORY_RESERVATION=4G 
